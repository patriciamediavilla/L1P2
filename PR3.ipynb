{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7uMDqLBxueCO+N/zGOM2i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patriciamediavilla/L1P2/blob/main/PR3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PILAR ARIAS, YEDRA MARTÍN, PATRICIA MEDIAVILLA, AMAYA SARASA\n",
        "\n",
        "<GRUPO 9>"
      ],
      "metadata": {
        "id": "3PGqz49Ix8ll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Práctica 3"
      ],
      "metadata": {
        "id": "PHhVwwvpx-En"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introducción"
      ],
      "metadata": {
        "id": "dReDrXPezjkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta es la tercera práctica del tercer laboratorio. En esta práctica se clasifican imágenes. Las imáenes van a ser números escritos a mano y gracias a la clasificación.\n",
        "Lo primero es cargar la base de datos con la que se va a trabajar, que es la de \"load_digits\" proporcionada por scikit-learn."
      ],
      "metadata": {
        "id": "v3Iqty2eyBqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos las librerias necesarias\n",
        "import numpy as np #numpy\n",
        "import pandas as pd #pandas\n",
        "import sklearn as sk #scikit-learn\n",
        "import matplotlib.pyplot as plt #gráfica Matplotlib\n",
        "import math\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "digits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAwr2n_vx1G0",
        "outputId": "e7550763-f108-46bb-bc75-f6e19fcbd593"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
              "        ...,\n",
              "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
              "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
              " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
              " 'frame': None,\n",
              " 'feature_names': ['pixel_0_0',\n",
              "  'pixel_0_1',\n",
              "  'pixel_0_2',\n",
              "  'pixel_0_3',\n",
              "  'pixel_0_4',\n",
              "  'pixel_0_5',\n",
              "  'pixel_0_6',\n",
              "  'pixel_0_7',\n",
              "  'pixel_1_0',\n",
              "  'pixel_1_1',\n",
              "  'pixel_1_2',\n",
              "  'pixel_1_3',\n",
              "  'pixel_1_4',\n",
              "  'pixel_1_5',\n",
              "  'pixel_1_6',\n",
              "  'pixel_1_7',\n",
              "  'pixel_2_0',\n",
              "  'pixel_2_1',\n",
              "  'pixel_2_2',\n",
              "  'pixel_2_3',\n",
              "  'pixel_2_4',\n",
              "  'pixel_2_5',\n",
              "  'pixel_2_6',\n",
              "  'pixel_2_7',\n",
              "  'pixel_3_0',\n",
              "  'pixel_3_1',\n",
              "  'pixel_3_2',\n",
              "  'pixel_3_3',\n",
              "  'pixel_3_4',\n",
              "  'pixel_3_5',\n",
              "  'pixel_3_6',\n",
              "  'pixel_3_7',\n",
              "  'pixel_4_0',\n",
              "  'pixel_4_1',\n",
              "  'pixel_4_2',\n",
              "  'pixel_4_3',\n",
              "  'pixel_4_4',\n",
              "  'pixel_4_5',\n",
              "  'pixel_4_6',\n",
              "  'pixel_4_7',\n",
              "  'pixel_5_0',\n",
              "  'pixel_5_1',\n",
              "  'pixel_5_2',\n",
              "  'pixel_5_3',\n",
              "  'pixel_5_4',\n",
              "  'pixel_5_5',\n",
              "  'pixel_5_6',\n",
              "  'pixel_5_7',\n",
              "  'pixel_6_0',\n",
              "  'pixel_6_1',\n",
              "  'pixel_6_2',\n",
              "  'pixel_6_3',\n",
              "  'pixel_6_4',\n",
              "  'pixel_6_5',\n",
              "  'pixel_6_6',\n",
              "  'pixel_6_7',\n",
              "  'pixel_7_0',\n",
              "  'pixel_7_1',\n",
              "  'pixel_7_2',\n",
              "  'pixel_7_3',\n",
              "  'pixel_7_4',\n",
              "  'pixel_7_5',\n",
              "  'pixel_7_6',\n",
              "  'pixel_7_7'],\n",
              " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
              " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
              "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
              "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
              "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
              "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
              "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
              "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
              "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
              "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
              "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
              "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
              "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
              "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
              "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
              "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
              "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
              " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos el dataset de la librería indicada.\n"
      ],
      "metadata": {
        "id": "wefzif7n5Ezg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Según se ha estudiado en clase, encontramos dos métodos para afrontarlo. Nos decantaremos por CRISP-DM. Las siglas para: CRoss-Industry Standard Process for Data Mining. \n",
        "\n",
        "Es un modelo de proceso de minería de datos que se utiliza en la industria. Es un marco de trabajo que define un proceso estandarizado para llevar a cabo proyectos de minería de datos, desde la definición del problema hasta la implementación y evaluación del resultado. Los seis pasos que componen Crisp-DM son los siguientes:\n",
        "\n",
        "- Comprensión de los negocios y definición del problema: comprender la naturaleza del problema y los objetivos de negocio.\n",
        "\n",
        "- Comprensión de los datos: recopilación inicial, descripción y exploración  de datos.\n",
        "\n",
        "- Preparación de los datos: Selección, limpieza, construcción, integración, formateo de los datos.\n",
        "\n",
        "- Modelado: aplicar las técnicas de minería de datos a los dataset.\n",
        "\n",
        "- Evaluación: determinar si los resultados son útiles a las necesidades del negocio.\n",
        "\n",
        "- Despliegue: explotar utilidad de los modelos, integrándolos en las tareas de toma de decisiones de la organización -> Call to Action. "
      ],
      "metadata": {
        "id": "AUWOs0ec7RUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comprensión de los negocios y definición del problema\n",
        "\n",
        "El etiquetado de imágenes es una tarea ardua. Es por ello y también debido a sus aplicaciones prácticas que\n",
        "los científicos llevan un tiempo intentando mejorar los métodos para clasificarlas automáticamente. En la\n",
        "oficina de correos de Pozuelo de Alarcón quieren poner en práctica un modelo que clasifique las cartas según\n",
        "el código postal escrito en ellas. Para ello vamos a crear un clasificador que leyendo un número escrito a mano\n",
        "pueda saber cuál es. Dicho clasificador funcionará mediante un set de entrenamiento donde se buscará un\n",
        "plano que divida las diferentes clases dispuesta en un espacio n-dimensional dependiendo de sus\n",
        "características.\n",
        "\n",
        "Para ello usaremos el dataset “load_digits” que se encuentra en scikit-learn. Elige el clasificador que más se\n",
        "adapte de entre los vistos en clase y usa scikit-learn junto con las librerías que necesites para resolver las\n",
        "siguientes cuestiones.\n",
        "\n",
        "1) Crea un clasificador que permita saber qué número es a partir de una imagen de este. Realiza al\n",
        "menos dos configuraciones y dibuja una tabla donde se muestre la precisión con la que clasifican.\n",
        "\n",
        "\n",
        "2) Elige 5 números que no hayas usado ni para entrenar el modelo, ni para evaluarlo y clasifícalas.\n",
        "Usa para ello el modelo que mejor clasifique de los del punto anterior. Índica con que error ha\n",
        "funcionado el clasificador. \n"
      ],
      "metadata": {
        "id": "Balnubyn7WBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comprensión de los datos"
      ],
      "metadata": {
        "id": "t1XM5kpy9RXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset que hemos descargado me devuelve un diccionario que contiene las siguientes claves:\n",
        "\n",
        "- Data: una matriz de tamaño (nº muestras, nº características) que contiene las imágenes de los dígitos.\n",
        "- Target: una matriz de tamaño (nº muestras), que contiene las etiquetas de los dígitos, es decir, los números que representan.\n",
        "- Target_names: una matriz de tamaño (nº clases), que contiene los nombres de las etiquetas, es decir, los números que representan.\n",
        "- Images: una matriz de tamaño (nº \n",
        "muestras, altura, anchura) que contiene las imágenes de los dígitos en forma de matriz.\n",
        "- DESCR: una cadena de texto que describe el conjunto de datos.\n"
      ],
      "metadata": {
        "id": "WH49-3Xk9XDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparación de los datos"
      ],
      "metadata": {
        "id": "Uyhb2HSK9d-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero se inspeccionan un poco más los datos.\n",
        "\n",
        "Se puede ver el tamaño del conjunto de datos, los nombres de las características, los valores de las características y los valores objetivo. \n"
      ],
      "metadata": {
        "id": "YDvXteqM9uoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(digits.data.shape)\n",
        "print(digits.feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF9Np2oY_E8b",
        "outputId": "2bdf24af-7346-43dc-9d87-e724d9344dd1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 64)\n",
            "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto indica que hay 1797 imágenes y cada imagen está representada por un vector de 64 características."
      ],
      "metadata": {
        "id": "Y2JRKZTt_KPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se ve si en el diccionario hay NaN"
      ],
      "metadata": {
        "id": "6xvzORPNCdiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if any([any([val != val for val in row]) for row in digits.data]):\n",
        "    print(\"Hay valores NaN en el conjunto de datos.\")\n",
        "else:\n",
        "    print(\"No hay valores NaN en el conjunto de datos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q58ZN81bCjY6",
        "outputId": "cd6c2a1a-d7ef-4e2e-cd28-5adba1f39a1c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No hay valores NaN en el conjunto de datos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora se ve que en el diccionario no hay valores vacíos."
      ],
      "metadata": {
        "id": "_7GYFUMSENGM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se visualizan los datos para tener una mejor comprensión de los mismos. Por ejemplo, se pueden trazar algunos ejemplos de imágenes para ver cómo se ven las imágenes y cómo están etiquetadas. "
      ],
      "metadata": {
        "id": "0dNRAfVH_TMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(6, 6))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "  ax.imshow(digits.data[:16][i].reshape(8, 8), cmap='gray')\n",
        "  ax.set(xticks=[], yticks=[])\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "9H5ZJzlZ_SMd",
        "outputId": "3f1d7e76-91ab-47ea-9322-b6ac6717833b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se observamos que estas imágenes, al igual es un poco confusa de reconocer, pero se diferencia perfectamente los números que se muestran (0,1,2,3,4,5,6,7,8,9,0,1,2,3,4,5) además se ve que las imágenes están en orden."
      ],
      "metadata": {
        "id": "Hx4d8VCjAz5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelado"
      ],
      "metadata": {
        "id": "C37AlaCBGqJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para aplicar este paso de la metodología CRISP-DM se aplica\n",
        "\n",
        "RELLENAR"
      ],
      "metadata": {
        "id": "wIgt6l8bGr4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "i8gOBwH6Gj7N"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8KC8c6uNC8W",
        "outputId": "d6d40d6f-49a4-4585-f676-8c5eacd3a750"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1437"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEMdJywNOnvX",
        "outputId": "4554c43c-c384-47c0-82ab-56c19bfc5d3a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1437"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indicesacomprobar =  np.random.randint(low=0, high=1437, size=5)\n",
        "indicesacomprobar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDiUQv6RNO_2",
        "outputId": "872dd3a2-fc1f-4bc0-8a9c-9251627e683e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 542,  634, 1107,  765,  640])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El conjunto definitivo quitando las 5 imágenes que depsues comprobamos"
      ],
      "metadata": {
        "id": "8A6Zw0sbNliL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.delete(X_train, indicesacomprobar, axis=0)\n",
        "y_train = np.delete(y_train, indicesacomprobar, axis=0)"
      ],
      "metadata": {
        "id": "YKuOy-6dNkBG"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHt_9iPJOlrd",
        "outputId": "63ce2481-56d3-4aab-c4b0-6fd8c9644935"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1432"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPQo2hE9Oh5v",
        "outputId": "5b55a415-5c54-4f76-e4a9-05ae53a3625d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1432"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se utiliza la técnica KNN y se entrenan los clasificadores."
      ],
      "metadata": {
        "id": "oa5xAnQ_HOJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Probamos: K=3\n",
        "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
        "knn3.fit(X_train, y_train)\n",
        "\n",
        "#Probamos: K=5\n",
        "knn5 = KNeighborsClassifier(n_neighbors=5)\n",
        "knn5.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "wsEFSDqoHcd0",
        "outputId": "b1ace4e0-3829-445f-c620-2391d61a9441"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se ve la precisión"
      ],
      "metadata": {
        "id": "2fMF8bZQHyBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred3 = knn3.predict(X_test)\n",
        "accuracy3 = accuracy_score(y_test, y_pred3)\n",
        "\n",
        "y_pred5 = knn5.predict(X_test)\n",
        "accuracy5 = accuracy_score(y_test, y_pred5)\n",
        "\n",
        "print(\"Precisión (K=3): {:.2f}\".format(accuracy3))\n",
        "print(\"Precisión (K=5): {:.2f}\".format(accuracy5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4T2HU0eH0SU",
        "outputId": "de8bcae7-3484-4c5f-a659-94fed50901b7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión (K=3): 0.98\n",
            "Precisión (K=5): 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para clasificar las imagenes se elige un modelo, en este caso se elige el clasificador (KNN) en concreto el k=5 porqur tiene más precisión que k=3"
      ],
      "metadata": {
        "id": "UWSInNi6IUPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "#Cargamos el modelo\n",
        "with open(\"knn_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(knn5, f)"
      ],
      "metadata": {
        "id": "hIaUqPSlKARj"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se eligen 5 imágenes al azar que no se hayan usado ni para entrenar ni para evaluar. Se puede utilizar una función de la librería matplotlib."
      ],
      "metadata": {
        "id": "AqfnLb3JKFGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comprobar = digits.data[[ 542,  634, 1107,  765,  640]]\n",
        "\n",
        "fig, axs = plt.subplots(1, 5)\n",
        "for i in range(5):\n",
        "    axs[i].imshow(comprobar[i].reshape(8, 8), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "N40tqkrYLBCH",
        "outputId": "5ba274ab-c182-47ac-be01-da15a82d23aa"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediccion = knn5.predict(comprobar)\n",
        "\n",
        "# Mostramos las predicciones\n",
        "print(prediccion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xio3L0mxLTJp",
        "outputId": "5b7b3547-dd89-4ff7-c387-645bf678d696"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6 7 1 9 4]\n"
          ]
        }
      ]
    }
  ]
}
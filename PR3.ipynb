{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1JkVZm2WZQuZ3YiKujeIo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patriciamediavilla/L1P2/blob/main/PR3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PILAR ARIAS, YEDRA MARTÍN, PATRICIA MEDIAVILLA, AMAYA SARASA\n",
        "\n",
        "<GRUPO 9>"
      ],
      "metadata": {
        "id": "3PGqz49Ix8ll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Práctica 3"
      ],
      "metadata": {
        "id": "PHhVwwvpx-En"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introducción"
      ],
      "metadata": {
        "id": "dReDrXPezjkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta es la tercera práctica del tercer laboratorio. En esta práctica vamos a clasificar imágenes. Las imáenes van a ser números escritos a mano y gracias a la clasificación.\n",
        "Lo primero es cargar la base de datos con la que vamos a trabajar, que es la de \"load_digits\" proporcionada por scikit-learn."
      ],
      "metadata": {
        "id": "v3Iqty2eyBqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos las librerias necesarias\n",
        "import numpy as np #numpy\n",
        "import pandas as pd #pandas\n",
        "import sklearn as sk #scikit-learn\n",
        "import matplotlib.pyplot as plt #gráfica Matplotlib\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "digits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAwr2n_vx1G0",
        "outputId": "cf9a9f9d-4d90-4100-b53f-88faf2b6ce8d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
              "        ...,\n",
              "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
              "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
              " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
              " 'frame': None,\n",
              " 'feature_names': ['pixel_0_0',\n",
              "  'pixel_0_1',\n",
              "  'pixel_0_2',\n",
              "  'pixel_0_3',\n",
              "  'pixel_0_4',\n",
              "  'pixel_0_5',\n",
              "  'pixel_0_6',\n",
              "  'pixel_0_7',\n",
              "  'pixel_1_0',\n",
              "  'pixel_1_1',\n",
              "  'pixel_1_2',\n",
              "  'pixel_1_3',\n",
              "  'pixel_1_4',\n",
              "  'pixel_1_5',\n",
              "  'pixel_1_6',\n",
              "  'pixel_1_7',\n",
              "  'pixel_2_0',\n",
              "  'pixel_2_1',\n",
              "  'pixel_2_2',\n",
              "  'pixel_2_3',\n",
              "  'pixel_2_4',\n",
              "  'pixel_2_5',\n",
              "  'pixel_2_6',\n",
              "  'pixel_2_7',\n",
              "  'pixel_3_0',\n",
              "  'pixel_3_1',\n",
              "  'pixel_3_2',\n",
              "  'pixel_3_3',\n",
              "  'pixel_3_4',\n",
              "  'pixel_3_5',\n",
              "  'pixel_3_6',\n",
              "  'pixel_3_7',\n",
              "  'pixel_4_0',\n",
              "  'pixel_4_1',\n",
              "  'pixel_4_2',\n",
              "  'pixel_4_3',\n",
              "  'pixel_4_4',\n",
              "  'pixel_4_5',\n",
              "  'pixel_4_6',\n",
              "  'pixel_4_7',\n",
              "  'pixel_5_0',\n",
              "  'pixel_5_1',\n",
              "  'pixel_5_2',\n",
              "  'pixel_5_3',\n",
              "  'pixel_5_4',\n",
              "  'pixel_5_5',\n",
              "  'pixel_5_6',\n",
              "  'pixel_5_7',\n",
              "  'pixel_6_0',\n",
              "  'pixel_6_1',\n",
              "  'pixel_6_2',\n",
              "  'pixel_6_3',\n",
              "  'pixel_6_4',\n",
              "  'pixel_6_5',\n",
              "  'pixel_6_6',\n",
              "  'pixel_6_7',\n",
              "  'pixel_7_0',\n",
              "  'pixel_7_1',\n",
              "  'pixel_7_2',\n",
              "  'pixel_7_3',\n",
              "  'pixel_7_4',\n",
              "  'pixel_7_5',\n",
              "  'pixel_7_6',\n",
              "  'pixel_7_7'],\n",
              " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
              " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
              "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
              "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
              "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
              "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
              "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
              "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
              "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
              "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
              "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
              "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
              "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
              "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
              "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
              "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
              "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
              " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos el dataset de la librería indicada.\n"
      ],
      "metadata": {
        "id": "wefzif7n5Ezg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Según se ha estudiado en clase, encontramos dos métodos para afrontarlo. Nos decantaremos por CRISP-DM. Las siglas para: CRoss-Industry Standard Process for Data Mining. \n",
        "\n",
        "Es un modelo de proceso de minería de datos que se utiliza en la industria. Es un marco de trabajo que define un proceso estandarizado para llevar a cabo proyectos de minería de datos, desde la definición del problema hasta la implementación y evaluación del resultado. Los seis pasos que componen Crisp-DM son los siguientes:\n",
        "\n",
        "- Comprensión de los negocios y definición del problema: comprender la naturaleza del problema y los objetivos de negocio.\n",
        "\n",
        "- Comprensión de los datos: recopilación inicial, descripción y exploración  de datos.\n",
        "\n",
        "- Preparación de los datos: Selección, limpieza, construcción, integración, formateo de los datos.\n",
        "\n",
        "- Modelado: aplicar las técnicas de minería de datos a los dataset.\n",
        "\n",
        "- Evaluación: determinar si los resultados son útiles a las necesidades del negocio.\n",
        "\n",
        "- Despliegue: explotar utilidad de los modelos, integrándolos en las tareas de toma de decisiones de la organización -> Call to Action. "
      ],
      "metadata": {
        "id": "AUWOs0ec7RUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comprensión de los negocios y definición del problema\n",
        "\n",
        "El etiquetado de imágenes es una tarea ardua. Es por ello y también debido a sus aplicaciones prácticas que\n",
        "los científicos llevan un tiempo intentando mejorar los métodos para clasificarlas automáticamente. En la\n",
        "oficina de correos de Pozuelo de Alarcón quieren poner en práctica un modelo que clasifique las cartas según\n",
        "el código postal escrito en ellas. Para ello vamos a crear un clasificador que leyendo un número escrito a mano\n",
        "pueda saber cuál es. Dicho clasificador funcionará mediante un set de entrenamiento donde se buscará un\n",
        "plano que divida las diferentes clases dispuesta en un espacio n-dimensional dependiendo de sus\n",
        "características.\n",
        "\n",
        "Para ello usaremos el dataset “load_digits” que se encuentra en scikit-learn. Elige el clasificador que más se\n",
        "adapte de entre los vistos en clase y usa scikit-learn junto con las librerías que necesites para resolver las\n",
        "siguientes cuestiones.\n",
        "\n",
        "1) Crea un clasificador que permita saber qué número es a partir de una imagen de este. Realiza al\n",
        "menos dos configuraciones y dibuja una tabla donde se muestre la precisión con la que clasifican.\n",
        "\n",
        "\n",
        "2) Elige 5 números que no hayas usado ni para entrenar el modelo, ni para evaluarlo y clasifícalas.\n",
        "Usa para ello el modelo que mejor clasifique de los del punto anterior. Índica con que error ha\n",
        "funcionado el clasificador. \n"
      ],
      "metadata": {
        "id": "Balnubyn7WBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comprensión de los datos"
      ],
      "metadata": {
        "id": "t1XM5kpy9RXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset que hemos descargado me devuelve un diccionario que contiene las siguientes claves:\n",
        "\n",
        "- Data: una matriz de tamaño (nº muestras, nº características) que contiene las imágenes de los dígitos.\n",
        "- Target: una matriz de tamaño (nº muestras), que contiene las etiquetas de los dígitos, es decir, los números que representan.\n",
        "- Target_names: una matriz de tamaño (nº clases), que contiene los nombres de las etiquetas, es decir, los números que representan.\n",
        "- Images: una matriz de tamaño (nº \n",
        "muestras, altura, anchura) que contiene las imágenes de los dígitos en forma de matriz.\n",
        "- DESCR: una cadena de texto que describe el conjunto de datos.\n"
      ],
      "metadata": {
        "id": "WH49-3Xk9XDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparación de los datos"
      ],
      "metadata": {
        "id": "Uyhb2HSK9d-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero vamos a inspeccionar un poco más los datos.\n",
        "\n",
        "Podemos inspeccionar el tamaño del conjunto de datos, los nombres de las características, los valores de las características y los valores objetivo. \n"
      ],
      "metadata": {
        "id": "YDvXteqM9uoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(digits.data.shape)\n",
        "print(digits.feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF9Np2oY_E8b",
        "outputId": "3beed21d-b0f0-4c81-9f8f-dbc19dcedcde"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 64)\n",
            "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto nos indica que hay 1797 imágenes y cada imagen está representada por un vector de 64 características."
      ],
      "metadata": {
        "id": "Y2JRKZTt_KPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos visualizar los datos para tener una mejor comprensión de los mismos. Por ejemplo, podemos trazar algunos ejemplos de imágenes para ver cómo se ven las imágenes y cómo están etiquetadas. "
      ],
      "metadata": {
        "id": "0dNRAfVH_TMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(6, 6))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "  ax.imshow(digits.data[:16][i].reshape(8, 8), cmap='gray')\n",
        "  ax.set(xticks=[], yticks=[])\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "9H5ZJzlZ_SMd",
        "outputId": "06c57545-3d91-4182-9c3d-9552fa361c01"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que estas imágenes, al igual es un poco confusa de reconocer, pero se diferencia perfectamente los números que nos muestran (0,1,2,3,4,5,6,7,8,9,0,1,2,3,4,5) además vemos que las imágenes están en orden."
      ],
      "metadata": {
        "id": "Hx4d8VCjAz5W"
      }
    }
  ]
}